# Transformer Tracking

This repository is a paper digest of Transformer-alike approaches in video tracking tasks. Currently, tasks in this repository include **Single Object Tracking (SOT)**, **Video Object Segmentation (VOS)**, **Multiple Object Tracking (MOT)**, **Object Re-Identification (ReID)**, **Video Instance Segmentation (VIS)** and **Video Object Detection (VOD)**. Note that some trackers with a non-local attention mechanism are also collected.



## :bookmark:Single Object Tracking (SOT)

### ICPR 2020:tada:

- **VTT** (VTT: Long-term Visual Tracking with Transformers) [[paper](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]

### CVPR 2021:tada:

- **SiamGAT** (Graph Attention Tracking) [[paper](https://arxiv.org/abs/2011.11204)]

- **STMTrack** (STMTrack: Template-free Visual Tracking with Space-time Memory Networks) [[paper](https://arxiv.org/abs/2104.00324)]

- **TransT** (Transformer Tracking) [[paper](https://arxiv.org/abs/2103.15436)]
- **TMT** (Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking) [[paper](https://arxiv.org/abs/2103.11681)]

### ICCV 2021:tada:

- **SAMN** (Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking) [[paper](https://arxiv.org/abs/2009.09669)]
- **HiFT** (HiFT: Hierarchical Feature Transformer for Aerial Tracking) [[paper](https://arxiv.org/abs/2108.00202)]
- **DTT** (High-Performance Discriminative Tracking With Transformers) [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.html)]
- **STARK** (Learning Spatio-Temporal Transformer for Visual Tracking) [[paper](https://arxiv.org/abs/2103.17154)]
- **DualTFR** (Learning Tracking Representations via Dual-Branch Fully Transformer Networks) [[paper](https://arxiv.org/abs/2112.02571)]

### CoRR 2021:tada:

- **TREG** (Target Transformed Regression for Accurate Tracking) [[paper](https://arxiv.org/abs/2104.00403)]
- **TrTr** (TrTr: Visual Tracking with Transformer) [[paper](https://arxiv.org/abs/2105.03817)]
- **E.T.Track** (Efficient Visual Tracking with Exemplar Transformers) [[paper](https://arxiv.org/abs/2112.09686)]
- **SwinTrack** (SwinTrack: A Simple and Strong Baseline for Transformer Tracking) [[paper](https://arxiv.org/abs/2112.00995)]

### WACV 2022:tada:

- **SiamTPN** (Siamese Transformer Pyramid Networks for Real-Time UAV Tracking) [[paper](https://arxiv.org/abs/2110.08822)]

### CoRR 2022:tada:

- **InMo** (Learning Target-aware Representation for Visual Tracking via Informative Interactions) [[paper](https://arxiv.org/abs/2201.02526)]



## :bookmark:Video Object Segmentation (VOS)

### ICCV 2019:tada:

- **STM** (Video Object Segmentation using Space-Time Memory Networks) [[paper](https://arxiv.org/abs/1904.00607)]

### ECCV 2020:tada:

- **KMN** (Kernelized Memory Network for Video Object Segmentation) [[paper](https://arxiv.org/abs/2007.08270)]
- **GCM** (Fast Video Object Segmentation using the Global Context Module) [[paper](https://arxiv.org/abs/2001.11243)]
- **GraphMemVOS** (Video Object Segmentation with Episodic Graph Memory Networks) [[paper](https://arxiv.org/abs/2007.07020)]

### NeurIPS 2020:tada:

- **AFB-URR** (Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement) [[paper](https://arxiv.org/abs/2010.07958)]

### AAAI 2021:tada:

- **STG-Net** (Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation) [[paper](https://arxiv.org/abs/2012.05499)]

### CVPR 2021:tada:

- **LCM** (Learning Position and Target Consistency for Memory-based Video Object Segmentation) [[paper](https://arxiv.org/abs/2104.04329)]
- **RMNet** (Efficient Regional Memory Network for Video Object Segmentation) [[paper](https://arxiv.org/abs/2103.12934)]
- **SwiftNet** (SwiftNet: Real-time Video Object Segmentation) [[paper](https://arxiv.org/abs/2102.04604)]
- **SSTVOS** (SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation) [[paper](https://arxiv.org/abs/2101.08833)]

### NeurIPS 2021:tada:

- **AOT** (Associating Objects with Transformers for Video Object Segmentation) [[paper](https://arxiv.org/abs/2106.02638)]
- **STCN** (Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation) [[paper](https://arxiv.org/abs/2106.05210)]

### CoRR 2021:tada:

- **TransVOS** (TransVOS: Video Object Segmentation with Transformers) [[paper](https://arxiv.org/abs/2106.00588)]

### WACV 2022:tada:

- **BMVOS** (Pixel-Level Bijective Matching for Video Object Segmentation) [[paper](https://arxiv.org/abs/2110.01644)]

### AAAI 2022:tada:

- **SITVOS** (Siamese Network with Interactive Transformer for Video Object Segmentation) [[paper](https://arxiv.org/abs/2112.13983)]



## :bookmark:Multiple Object Tracking (MOT)

### CoRR 2021:tada:

- **RelationTrack** (RelationTrack: Relation-aware Multiple Object Tracking with Decoupled Representation) [[paper](https://arxiv.org/abs/2105.04322)]
- **TransTrack** (TransTrack: Multiple Object Tracking with Transformer) [[paper](https://arxiv.org/abs/2012.15460)]
- **TrackFormer** (TrackFormer: Multi-Object Tracking with Transformers) [[paper](https://arxiv.org/abs/2101.02702)]
- **TransMOT** (TransMOT: Spatial-Temporal Graph Transformer for Multiple Object Tracking) [[paper](https://arxiv.org/abs/2104.00194)]
- **TransCenter** (TransCenter: Transformers with Dense Queries for Multiple-Object Tracking) [[paper](https://arxiv.org/abs/2103.15145)]
- **MOTR** (MOTR: End-to-End Multiple-Object Tracking with TRansformer) [[paper](https://arxiv.org/abs/2105.03247)]
- **MO3TR** (Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers) [[paper](https://arxiv.org/abs/2103.14829)]



##  :bookmark:Object Re-Identification (ReID)

### ICCV 2021:tada:

- **TransReID** (TransReID: Transformer-based Object Re-Identification) [[paper](https://arxiv.org/abs/2102.04378)]

### MM 2021:tada:

- **HAT** (HAT: Hierarchical Aggregation Transformers for Person Re-identification) [[paper](https://arxiv.org/abs/2107.05946)]

### CoRR 2021:tada:

- **TMT** (A Video Is Worth Three Views: Trigeminal Transformers for Video-based Person Re-identification) [[paper](https://arxiv.org/abs/2104.01745)]
- **STT** (Spatiotemporal Transformer for Video-based Person Re-identification) [[paper](https://arxiv.org/abs/2103.16469)]



## :bookmark:Video Instance Segmentation (VIS)

### CVPR 2021:tada:

- **VisTR** (End-to-End Video Instance Segmentation with Transformers) [[paper](https://arxiv.org/abs/2011.14503)]

### NeurIPS 2021:tada:

- **IFC** (Video Instance Segmentation using Inter-Frame Communication Transformers) [[paper](https://arxiv.org/abs/2106.03299)]

### CoRR 2021:tada:

- **QueryTrack** (Tracking Instances as Queries) [[paper](https://arxiv.org/abs/2106.11963)]



## :bookmark:Video Object Detection (VOD)

### CoRR 2021:tada:

- **TransVOD** (End-to-End Video Object Detection with Spatial-Temporal Transformers) [[paper](https://arxiv.org/abs/2105.10920)]

### CoRR 2022:tada:

- **TransVOD++** (TransVOD: End-to-end Video Object Detection with Spatial-Temporal Transformers) [[paper](https://arxiv.org/abs/2201.05047)]

