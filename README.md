# Transformer Tracking

This repository is a paper digest of [Transformer](https://arxiv.org/abs/1706.03762)-related approaches in vision tracking tasks. Currently, tasks in this repository include **Unified Tracking (UT)** and **Single Object Tracking (SOT)**. Note that some trackers involving a [Non-Local](https://arxiv.org/abs/1711.07971) attention mechanism are also collected. Papers are listed in alphabetical order of the first character.



## :star2:Recommendation

### ECCV 2022:two_hearts::two_hearts::two_hearts:

- **AiATrack** (AiATrack: Attention in Attention for Transformer Visual Tracking) [[link](https://arxiv.org/abs/2207.09603)]



## :bookmark:Unified Tracking (UT)

### CVPR 2022:tada::tada::tada:

- **UTT** (Unified Transformer Tracker for Object Tracking) [[link](https://arxiv.org/abs/2203.15175)]

### ECCV 2022:tada::tada::tada:

- **Unicorn** (Towards Grand Unification of Object Tracking) [[link](https://arxiv.org/abs/2207.07078)]



## :bookmark:Single Object Tracking (SOT)

### CVPR 2022:tada::tada::tada:

- **CSWinTT** (Transformer Tracking with Cyclic Shifting Window Attention) [[link](https://arxiv.org/abs/2205.03806)]
- **GTELT** (Global Tracking via Ensemble of Local Trackers) [[link](https://arxiv.org/abs/2203.16092)]
- **MixFormer** (MixFormer: End-to-End Tracking with Iterative Mixed Attention) [[link](https://arxiv.org/abs/2203.11082)]
- **RBO** (Ranking-Based Siamese Visual Tracking) [[link](https://arxiv.org/abs/2205.11761)]
- **SBT** (Correlation-Aware Deep Tracking) [[link](https://arxiv.org/abs/2203.01666)]
- **STNet** (Spiking Transformers for Event-based Single Object Tracking) [[link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)]
- **TCTrack** (TCTrack: Temporal Contexts for Aerial Tracking) [[link](https://arxiv.org/abs/2203.01885)]
- **ToMP** (Transforming Model Prediction for Tracking) [[link](https://arxiv.org/abs/2203.11192)]
- **UDAT** (Unsupervised Domain Adaptation for Nighttime Aerial Tracking) [[link](https://arxiv.org/abs/2203.10541)]
- **UTT** (Unified Transformer Tracker for Object Tracking) [[link](https://arxiv.org/abs/2203.15175)]

### ECCV 2022:tada::tada::tada:

- **AiATrack** (AiATrack: Attention in Attention for Transformer Visual Tracking) [[link](https://arxiv.org/abs/2207.09603)]
- **OSTrack** (Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework) [[link](https://arxiv.org/abs/2203.11991)]
- **SimTrack** (Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking) [[link](https://arxiv.org/abs/2203.05328)]
- **Unicorn** (Towards Grand Unification of Object Tracking) [[link](https://arxiv.org/abs/2207.07078)]

### AAAI 2022

- **APFNet** (Attribute-based Progressive Fusion Network for RGBT Tracking) [[link](https://aaai-2022.virtualchair.net/poster_aaai7747)]

### IJCAI 2022

- **InBN** (Learning Target-aware Representation for Visual Tracking via Informative Interactions) [[link](https://arxiv.org/abs/2201.02526)]
- **SparseTT** (SparseTT: Visual Tracking with Sparse Transformers) [[link](https://arxiv.org/abs/2205.03776)]

### MICCAI 2022

- **TLT** (Transformer Lesion Tracker) [[link](https://arxiv.org/abs/2206.06252)]

### WACV 2022

- **SiamTPN** (Siamese Transformer Pyramid Networks for Real-Time UAV Tracking) [[link](https://arxiv.org/abs/2110.08822)]

### Preprint 2022

- **HCAT** (Efficient Visual Tracking via Hierarchical Cross-Attention Transformer) [[link](https://arxiv.org/abs/2203.13537)]
- **SiamLA** (Learning Localization-aware Target Confidence for Siamese Visual Tracking) [[link](https://arxiv.org/abs/2204.14093)]
- **TransT-M** (High-Performance Transformer Tracking) [[link](https://arxiv.org/abs/2203.13533)]

### CVPR 2021:tada::tada::tada:

- **SiamGAT** (Graph Attention Tracking) [[link](https://arxiv.org/abs/2011.11204)]
- **STMTrack** (STMTrack: Template-free Visual Tracking with Space-time Memory Networks) [[link](https://arxiv.org/abs/2104.00324)]
- **TMT** (Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking) [[link](https://arxiv.org/abs/2103.11681)]
- **TransT** (Transformer Tracking) [[link](https://arxiv.org/abs/2103.15436)]

### ICCV 2021:tada::tada::tada:

- **AutoMatch** (Learn to Match: Automatic Matching Network Design for Visual Tracking) [[link](https://arxiv.org/abs/2108.00803)]
- **DTT** (High-Performance Discriminative Tracking With Transformers) [[link](https://openaccess.thecvf.com/content/ICCV2021/html/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.html)]
- **DualTFR** (Learning Tracking Representations via Dual-Branch Fully Transformer Networks) [[link](https://arxiv.org/abs/2112.02571)]
- **HiFT** (HiFT: Hierarchical Feature Transformer for Aerial Tracking) [[link](https://arxiv.org/abs/2108.00202)]
- **SAMN** (Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking) [[link](https://arxiv.org/abs/2009.09669)]
- **STARK** (Learning Spatio-Temporal Transformer for Visual Tracking) [[link](https://arxiv.org/abs/2103.17154)]

### BMVC 2021

- **TAPL** (TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part Localization) [[link](https://arxiv.org/abs/2110.13027)]

### Preprint 2021

- **E.T.Track** (Efficient Visual Tracking with Exemplar Transformers) [[link](https://arxiv.org/abs/2112.09686)]
- **SwinTrack** (SwinTrack: A Simple and Strong Baseline for Transformer Tracking) [[link](https://arxiv.org/abs/2112.00995)]
- **TREG** (Target Transformed Regression for Accurate Tracking) [[link](https://arxiv.org/abs/2104.00403)]
- **TrTr** (TrTr: Visual Tracking with Transformer) [[link](https://arxiv.org/abs/2105.03817)]

### CVPR 2020:tada::tada::tada:

- **SiamAttn** (Deformable Siamese Attention Networks for Visual Object Tracking) [[link](https://arxiv.org/abs/2004.06711)]

### ICPR 2020

- **VTT** (VTT: Long-term Visual Tracking with Transformers) [[link](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]
